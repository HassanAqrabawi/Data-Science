import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import os
df=pd.read_csv("healthcare-dataset-stroke-data.csv")
df.head()

bmi_mean = df['bmi'].mean()
df['bmi'] = df['bmi'].fillna(bmi_mean)
missing_values_count = df.isna().sum()
print(df.info())
print(df)
# Drop the 'id' column from the DataFrame
df = df.drop('id', axis=1)
df['avg_glucose_level'] = df['avg_glucose_level'].apply(lambda x: int(x / 10) * 10)
df['age'] = df['age'].apply(lambda x: int(x / 10) * 10)
df['bmi'] = df['bmi'].apply(lambda x: int(x / 5) * 5)
df['gender'] = df['gender'].apply(lambda x: 1 if x == 'Male' else 0)
df['Residence_type'] = df['Residence_type'].apply(lambda x: 1 if x == 'Urban' else 0)


work_type_map = {'Private': 0, 'Self-employed': 1, 'Govt_job': 2, 'children': 3, 'Never_worked': 4}
df['work_type'] = df['work_type'].map(work_type_map)

smoking_status_map = {'never smoked': 0, 'formerly smoked': 1, 'smokes': 2, 'Unknown': 3}
df['smoking_status'] = df['smoking_status'].map(smoking_status_map)

df['ever_married'] = df['ever_married'].apply(lambda x: 1 if x == 'Yes' else 0)

# df.work_type.unique()
# df.Residence_type.unique()
df.smoking_status.unique()
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import train_test_split

import tensorflow as tf
from tensorflow.keras.optimizers import Adam 
from keras.callbacks import ReduceLROnPlateau, EarlyStopping
from keras.utils import to_categorical
from keras.preprocessing import image
from keras.applications.inception_v3 import InceptionV3
from keras.layers import (Input, Dense, Dropout, Activation, ZeroPadding2D, 
                          BatchNormalization, Flatten, Conv2D, Embedding, Add,
                          Conv1D, GlobalAveragePooling1D, AveragePooling2D, 
                          MaxPooling2D, MaxPool1D, ZeroPadding1D, 
                          GlobalMaxPooling2D, GlobalAveragePooling2D, LSTM, SpatialDropout1D)
from keras.models import Sequential, Model
from keras.layers import Dense, Activation, Flatten, Convolution1D, Dropout, MaxPooling1D
from keras.utils import plot_model
from keras import layers

import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import LabelEncoder

df = df.sample(frac=1).reset_index(drop=True)

y = df['stroke']
x = df.iloc[:, 0:11].astype(np.float32)

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)

# Print shape of data
print("train X shape=" + str(x_train.shape))
print("train y shape=" + str(y_train.shape))
print("test X shape=" + str(x_test.shape))
print("test y shape=" + str(y_test.shape))

ann_model = Sequential([
    Dense(64, activation='relu', input_shape=(11,)),
    Dense(64, activation='relu'),
    Dense(32, activation='relu'),
    Dense(32, activation='relu'),
    Dense(2, activation='softmax')
])

# Compile the model
ann_model.compile(optimizer=Adam(lr=0.0001),
                  loss='sparse_categorical_crossentropy',
                  metrics=['accuracy'])

# Plot the model architecture
tf.keras.utils.plot_model(
    ann_model,
    to_file='ann_model.png',
    show_shapes=True,
    show_layer_names=True
)
ann_model.summary()
history = ann_model.fit(x_train, y_train,batch_size= 15,
epochs=30,
verbose=1,
validation_data = (x_test, y_test))
# Plot the loss and accuracy curves for training and validation 
fig, (ax1, ax2) = plt.subplots(nrows=2, ncols=1, figsize=(10, 8))

ax1.plot(history.history['loss'], color='b', label="Training loss")
ax1.plot(history.history['val_loss'], color='orange', label="Validation loss")
ax1.legend(loc='best', shadow=True)

ax2.plot(history.history['accuracy'], color='b', label="Training accuracy")
ax2.plot(history.history['val_accuracy'], color='orange',label="Validation accuracy")
ax2.legend(loc='best', shadow=True)

plt.show()

